{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76cddb45",
   "metadata": {},
   "source": [
    "# Tutorial Notebook for Hunstead Lecture II: \n",
    "# Bayesian Inference and the Logic of Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d25f1",
   "metadata": {},
   "source": [
    "## Problem 1: The Curse of Dimensionality\n",
    "\n",
    "### 1a) Sampling in low dimensions\n",
    "\n",
    "Generate a sample of 100 randomly distributed points inside a 2D square. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "904be433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rand_2d_set = np.dstack((np.random.rand(100),np.random.rand(100)))\n",
    "rand_2d_set = np.squeeze(rand_2d_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a32c8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_2d_set[0]\n",
    "len(rand_2d_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a9fced",
   "metadata": {},
   "source": [
    "### 1b) Distances in low dimensions\n",
    "\n",
    "Calculate the pairwise distances between all of the points, in d-dimensions, for two points x_i and y_i, this quantity is\n",
    "\n",
    "$$ |x - y| = \\sqrt{\\Sigma^d (x_i - y_i)^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f18a6575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24920957503678332"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for point_num in range(len(rand_2d_set)):\n",
    "    array_dist = np.zeros(len(rand_2d_set) - 1)\n",
    "    dist = np.sqrt( np.power( rand_2d_set[0][0] - rand_2d_set[1][0], 2) + np.power( rand_2d_set[0][1] - rand_2d_set[1][1], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b239527",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1c) Distribution of distances in low dimensions \n",
    "\n",
    "Plot the distribution of these distances. Do you notice anything interesting? Is a \"special value\" picked out?\n",
    "\n",
    "### 1d) Extending to d-dimensions\n",
    "\n",
    "Now, let's consider the difference between picking a point located in a d-dimensional sphere vs in a d-dimensional cube. To do this, calculate and plot the the difference between the volume of a cube with unit-length sides and the volume of a unit-radius sphere as the dimension d of the space increases. Possibly helpful formula: \n",
    "\n",
    "$$ Sphere: V_d = \\frac{\\pi^{d/2}}{\\frac{d}{2} \\Gamma(\\frac{d}{2})} $$\n",
    "\n",
    "$$ Cube: V_d = L^d $$\n",
    "\n",
    "The proof of this formula is left as an exercise to the reader. \n",
    "\n",
    "### 1e) Sampling in d-dimensions\n",
    "\n",
    "Now, consider the problem of sampling in high-dimensions. If we use a uniform prior on every parameter, our expectation is that we will well sample the parameter space simply by picking in a \"uniform way\". Calculate the ratio of volume contained in an annulus between $R$ and $R - \\epsilon$ for d = 1-20 and plot this. Interpret your result in terms of a sampling problem. Are uniform priors a good choice in higher dimensions? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b86c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "743b4a42",
   "metadata": {},
   "source": [
    "## Problem 2: Probability Transformations in Astronomy\n",
    "\n",
    "This example comes from the documentation for the AstroML package, a very useful collection of statistics and ML tools written by astronomers. It is a famous example of where a common transformation in astronomy does not preserve all of the properties of the underlying distribution. \n",
    "\n",
    "### Problem 2a) Generate some underlying normally distributed flux data\n",
    "\n",
    "Hint: you can do this most easily with scipy.stats.norm(), norm.rvs. Your life in 4d) will be slightly easier if you generate an odd number of samples.\n",
    "\n",
    "### Problem 2b) Transform fluxes to magnitudes\n",
    "\n",
    "The magnitude of a source is defined as mag $= -2.5 \\log_{10}(F)$. transform your normally distributed flux data to magnitudes. \n",
    "\n",
    "### Problem 2c) Plot your results\n",
    "\n",
    "Plot the flux and magnitude distribution. How has the transformation changed the shape of the distribution?\n",
    "\n",
    "### Problem 2d) Cumulative Distribution Function\n",
    "\n",
    "Plot the CDF of each distribution and discuss the properties of the CDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee32f1",
   "metadata": {},
   "source": [
    "## Problem 3: Not everything is Gaussian (and some Practice with Bayes Theorem)\n",
    "\n",
    "The Gaussian distribution is very common, but not universal. In a (perhaps apocryphal story) this problem was given to first year students at Cambridge in the 1980s. It concerns estimating the distance to an off-shore lighthouse based on the timing of pulses. A canonical statement of the problem is, \n",
    "\n",
    "\"A lighthouse is situated at unknown coordinates $x_0,y_0$ with respect to a straight coastline y=0. It sends a series of N flashes in random directions, and these are recorded on the coastline at positions $x_i$.\" \n",
    "\n",
    "### Problem 3-0) Draw the picture. \n",
    "\n",
    "Start by drawing the picture. It is very useful.\n",
    "\n",
    "### Problem 3a) Prior \n",
    "\n",
    "Write down a prior for the $x_0, y_0$ position of the lighthouse. Implement a python function that returns a uniform probability (or if you'd like, another prior) for $x_0, y_0$. Hint: It is easier to write the prior in terms of the angle $\\theta$ between the line connecting the lighthouse to the shore and the direction in which the pulse is emitted. \n",
    "\n",
    "### Problem 3b) Likelihood \n",
    "\n",
    "Now, we need to determine the form of the likelihood. If you following the hint in 3a), we want to turn a function of the data (shoreline positions, x) in terms of the angle ($\\theta$). First, write down the relationship between the $x_0$ position of the lighthouse, the data x, and the angle ($\\theta$). \n",
    "\n",
    "### Problem 3c) Generate some data\n",
    "\n",
    "In order to produce a Bayesian estimate of the x-y position, we'll need some data. \n",
    "\n",
    "### Problem 3d) Posterior\n",
    "\n",
    "Using Bayes' theorem, write down the posterior. Implement a grid search function to calculate the posterior for the x-y position of the lighthouse. \n",
    "\n",
    "\n",
    "### Problem 3e) [Optional] Challenge: Is your likelihood a Gaussian? What is special about your likelihood?\n",
    "\n",
    "One property of a Gaussian that makes it \"special\" is that it is the maximum entropy distribution for for finite first and second moments. Calculate the first and second moments of your likelihood distribution. What makes this distribution special? Generate some example plots of your likelihood function and compare to a Gaussian distribution over the same range. Are these curves the same? What is different about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa12ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
